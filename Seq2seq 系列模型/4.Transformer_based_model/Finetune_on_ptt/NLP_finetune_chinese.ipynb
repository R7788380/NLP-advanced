{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"NLP_finetune_chinese.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0d5bcc896c214004bdd2abb2246f73bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8154ae5e671148a99997cbb5f19cff62","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2e335a8993ef45b391b34c77a71446de","IPY_MODEL_34072a70144e44a195797657918d09c0"]}},"8154ae5e671148a99997cbb5f19cff62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2e335a8993ef45b391b34c77a71446de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b737fb84bf8e4ebeb2c7b0dfcbdd997e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":624,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":624,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_168da643b46b46b98429e04c240bf5c0"}},"34072a70144e44a195797657918d09c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0da8d33919a146298a58667e596f6aa1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 624/624 [00:00&lt;00:00, 802B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cfef9ce3931b4eaeba413f65fb9e41c7"}},"b737fb84bf8e4ebeb2c7b0dfcbdd997e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"168da643b46b46b98429e04c240bf5c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0da8d33919a146298a58667e596f6aa1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cfef9ce3931b4eaeba413f65fb9e41c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"177ed4e50d2948618c48751668dc31dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c509a96653d643ab9a240f33c0c467b1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f029603c65174062ab4df35d4d3574ea","IPY_MODEL_5482f106497e4f1e856987ed2af606a7"]}},"c509a96653d643ab9a240f33c0c467b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f029603c65174062ab4df35d4d3574ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_59140716e7f749c8aa3dafd457a99085","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":478309336,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":478309336,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2e2f36a7474045dd8f5ade23e78b7fa4"}},"5482f106497e4f1e856987ed2af606a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b229c5cbcef04fe3ab567a18f5f014bf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 478M/478M [00:21&lt;00:00, 22.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cfed93ff5c6f44c083ed45a08f1a7d3c"}},"59140716e7f749c8aa3dafd457a99085":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2e2f36a7474045dd8f5ade23e78b7fa4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b229c5cbcef04fe3ab567a18f5f014bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cfed93ff5c6f44c083ed45a08f1a7d3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6618f04d4e8c4750b2afeebde16079fb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a6d62646a7024c8bba0dfad89ff34e66","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_05d44770060445219430c9be87e48278","IPY_MODEL_0d37d0618b584589ad73644bc024a6de"]}},"a6d62646a7024c8bba0dfad89ff34e66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"05d44770060445219430c9be87e48278":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_50fb5d156c0245f1b1557f11507daf12","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":109540,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":109540,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6f548925824f42ee9cb1a59ddee88f5e"}},"0d37d0618b584589ad73644bc024a6de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a7b380616b0f48dfbc8e6f2bae17219b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 110k/110k [00:00&lt;00:00, 189kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c3a3aebb7e5940c5a4dcaf6eb1e84b57"}},"50fb5d156c0245f1b1557f11507daf12":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6f548925824f42ee9cb1a59ddee88f5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a7b380616b0f48dfbc8e6f2bae17219b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c3a3aebb7e5940c5a4dcaf6eb1e84b57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ubMPyQpkoTCC","executionInfo":{"status":"ok","timestamp":1605774714969,"user_tz":-480,"elapsed":26766,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"7f61dd48-1275-46a4-9cb7-cfbf13869c39"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zPgv1VInn3Cb","executionInfo":{"status":"ok","timestamp":1605774595483,"user_tz":-480,"elapsed":1486,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"9066d14a-fb49-4607-a575-822265d8aad1"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Thu Nov 19 08:29:56 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    24W / 300W |      0MiB / 16130MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Pl_CrOJoBw3","executionInfo":{"status":"ok","timestamp":1605774625350,"user_tz":-480,"elapsed":11059,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"c9e20fbe-56b3-4f50-a8f7-f2d0768118de"},"source":["!pip install transformers\n","!pip install sacremoses"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 5.6MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 12.8MB/s \n","\u001b[?25hCollecting sentencepiece==0.1.91\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 28.2MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Collecting tokenizers==0.9.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 38.2MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=620dc9823a159ff66dc43c4bf780b208959d8e37e90689df9884b533b37f9781\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (0.0.43)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (0.17.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from sacremoses) (2019.12.20)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.15.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses) (4.41.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"v9-YIwfkaMQe"},"source":["# PTT gossip classification\n","\n","這章節我們使用中文預訓練模型 `bert-base-chinese` 來進行 `finetune` 。"]},{"cell_type":"code","metadata":{"id":"WaBnQxKlaMQf"},"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import numpy as np\n","import pandas as pd\n","import os\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","from sklearn.model_selection import train_test_split\n","from transformers import TFBertForSequenceClassification, BertTokenizer, glue_convert_examples_to_features\n","\n","os.chdir('/content/drive/Shareddrives/類技術班教材/標準版/NLP進階/Seq2seq 系列模型/4.Transformer_based_model/Finetune_on_ptt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224,"referenced_widgets":["0d5bcc896c214004bdd2abb2246f73bd","8154ae5e671148a99997cbb5f19cff62","2e335a8993ef45b391b34c77a71446de","34072a70144e44a195797657918d09c0","b737fb84bf8e4ebeb2c7b0dfcbdd997e","168da643b46b46b98429e04c240bf5c0","0da8d33919a146298a58667e596f6aa1","cfef9ce3931b4eaeba413f65fb9e41c7","177ed4e50d2948618c48751668dc31dd","c509a96653d643ab9a240f33c0c467b1","f029603c65174062ab4df35d4d3574ea","5482f106497e4f1e856987ed2af606a7","59140716e7f749c8aa3dafd457a99085","2e2f36a7474045dd8f5ade23e78b7fa4","b229c5cbcef04fe3ab567a18f5f014bf","cfed93ff5c6f44c083ed45a08f1a7d3c"]},"id":"pnd61CmHaMQf","executionInfo":{"status":"ok","timestamp":1605774662250,"user_tz":-480,"elapsed":28137,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"3dc9c596-194f-43ad-d069-540c35648a2f"},"source":["model = TFBertForSequenceClassification.from_pretrained('bert-base-chinese')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d5bcc896c214004bdd2abb2246f73bd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=624.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"177ed4e50d2948618c48751668dc31dd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=478309336.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-chinese were not used when initializing TFBertForSequenceClassification: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['dropout_37', 'classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["6618f04d4e8c4750b2afeebde16079fb","a6d62646a7024c8bba0dfad89ff34e66","05d44770060445219430c9be87e48278","0d37d0618b584589ad73644bc024a6de","50fb5d156c0245f1b1557f11507daf12","6f548925824f42ee9cb1a59ddee88f5e","a7b380616b0f48dfbc8e6f2bae17219b","c3a3aebb7e5940c5a4dcaf6eb1e84b57"]},"id":"xGLa2uFiaMQf","executionInfo":{"status":"ok","timestamp":1605774663935,"user_tz":-480,"elapsed":29622,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"fa2c9e0a-0abc-45c6-d603-4ae6aa6a5336"},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6618f04d4e8c4750b2afeebde16079fb","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=109540.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6-KgTTGyaMQf"},"source":["### Data overview\n","\n","我們使用從 ptt 八卦版進行爬蟲整理，$0$ 表示該留言的推數小於噓數，$1$ 表示該留言的推數大於噓數，所以這個任務是屬於 `Text classification` 任務 (二元分類)。"]},{"cell_type":"code","metadata":{"id":"DE2r9qAvaMQf"},"source":["ptt = pd.read_csv('Data/ptt_gossip.csv')\n","\n","bert_max_length = 512\n","ptt['sentence'] = [t[:bert_max_length] for t in ptt.sentence]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"5XSiTtWJaMQf","executionInfo":{"status":"ok","timestamp":1605775168340,"user_tz":-480,"elapsed":753,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"fafb9204-effa-45ed-ce95-7253e5c24bcf"},"source":["ptt.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>idx</th>\n","      <th>sentence</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>反核人士最愛靠妖 核電廠蓋你家好不好，我當然說好 核廢料放我家好不好，我也ok 放在地下室就...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>如標題， 今天去逛才看到的，如下圖所示:  位置在西屯區漢口路二段118號。 少了一個可以看...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>新聞來源  2025非核家園，燃煤電廠30%、再生能源(綠能)20%、 天然氣發電50%的能...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>牽了一台新的摩托車 車行老闆跟我說記得汽油要加95 還附帶 我開車行幾十年了 聽我的準沒錯 ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>各位30cm大大、F cup的水水，打給後 胎嘎後 本魯邊緣人，平日臉書沒朋友近日更4鬼怪肆...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   idx                                           sentence  label\n","0    0  反核人士最愛靠妖 核電廠蓋你家好不好，我當然說好 核廢料放我家好不好，我也ok 放在地下室就...      1\n","1    1  如標題， 今天去逛才看到的，如下圖所示:  位置在西屯區漢口路二段118號。 少了一個可以看...      1\n","2    2  新聞來源  2025非核家園，燃煤電廠30%、再生能源(綠能)20%、 天然氣發電50%的能...      1\n","3    3  牽了一台新的摩托車 車行老闆跟我說記得汽油要加95 還附帶 我開車行幾十年了 聽我的準沒錯 ...      1\n","4    4  各位30cm大大、F cup的水水，打給後 胎嘎後 本魯邊緣人，平日臉書沒朋友近日更4鬼怪肆...      1"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"wTFGCyyZaMQg"},"source":["\"\"\"\n","訓練集80%，測試集20%\n","\"\"\"\n","train_size = 0.8\n","\n","mask = np.random.rand(len(ptt)) < train_size\n","train_dataset = ptt[mask]\n","valid_dataset = ptt[~mask]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z-5uMCiJaMQg"},"source":["train_size = len(train_dataset)\n","valid_size = len(valid_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6VlEZW53aMQg","executionInfo":{"status":"ok","timestamp":1605775169829,"user_tz":-480,"elapsed":1206,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"e783aa8a-28cc-4706-d502-fb88b231ef44"},"source":["print('Train size: ', train_size)\n","print('Valid size: ', valid_size)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train size:  5656\n","Valid size:  1419\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FKJK21HNaMQg"},"source":["### Convert to tensor\n","\n","大部分 `Transformer` 預訓練模型都支持 `tf.tensor` 輸入格式，需要將資料集轉為`tf.tensor`格式。"]},{"cell_type":"code","metadata":{"id":"Z631leUwaMQg"},"source":["train_dataset = tf.data.Dataset.from_tensor_slices(dict(train_dataset))\n","valid_dataset = tf.data.Dataset.from_tensor_slices(dict(valid_dataset))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qKNDydukaMQg"},"source":["### Traing data format\n","\n","使用 `glue_convert_examples_to_features` 將資料集轉為模型可讀取格式，因為是二元分類，所以我們使用的任務為 `cola`，`cola` 是 `bert` 在 `finetune` 時的任務之一，一樣是二元分類任務，我們可以套用他的輸入格式來進行轉換，而在中文部分目前的預訓練模型都是用 `chararcter-level` 進行斷詞，所以我們將 `max_length` 提高至 $256$，下表為在 `Titan X 12G` 上 `finetune` 的參數限制，表示模型以及多少句子長度對應其最大的`batch_size`，需要注意其硬體限制。"]},{"cell_type":"markdown","metadata":{"id":"FGpLBu8PaMQg"},"source":["<figure>\n","<center>\n","<img src='https://drive.google.com/uc?export=view&id=1eudsSECQlf8SnfqAkJ0w65o8uwd_FnjW' width=\"300\"/>\n","<figcaption>Self-attention</figcaption></center>\n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"s4TNr0Vj2fzX"},"source":["接下來我們需要將資料集轉換成模型可讀取的格式，輸入格式有三個：\n","\n","* `input_ids`: 這表示句子斷完詞之後轉成 `token embeddings`，每一個詞有一個 `id`，如下圖，其中 `101` 表示 `[CLS]`，`102` 表示 `[SEP]`，因為 `MPRC` 是 `Sentence-Pair classification` 任務，所以下面的範例中會看到兩個 `102`。\n","\n","* `attention mask`: 因為 `Transformer` 會限制輸入句子的長度，最大限制為 `512`，而我們選擇 `128`，但不是所有的句子長度都是 `128`，所以需要在後面進行 `padding` (就是補0)，最主要的目的是不去計算 `padding` 位置的 `loss` 。\n","\n","* `token_type_ids`: 用來表示 `Segment embedding`，如上圖，表示詞屬於哪一個句子，因為 `MRPC` 有兩個句子，所以 `ids` 有2種，`0` 和 `1`。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fV4Z5p3SaMQg","executionInfo":{"status":"ok","timestamp":1605775304701,"user_tz":-480,"elapsed":9842,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"bdabf2d8-f88f-43a5-bb50-bd41aae81295"},"source":["max_length = 512\n","task = 'cola'\n","\n","train_dataset = glue_convert_examples_to_features(train_dataset,\n","                                                  tokenizer,\n","                                                  max_length,\n","                                                  task)\n","valid_dataset = glue_convert_examples_to_features(valid_dataset,\n","                                                  tokenizer,\n","                                                  max_length,\n","                                                  task)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/processors/glue.py:67: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/processors/glue.py:284: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"HV2Udn6IaMQg"},"source":["train_temp = next(iter(train_dataset))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WYAT8m9QaMQg","executionInfo":{"status":"ok","timestamp":1605775306034,"user_tz":-480,"elapsed":723,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"f4e76ed7-59dc-418a-ad77-b8038cd02551"},"source":["train_temp"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'attention_mask': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n","  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0], dtype=int32)>,\n","  'input_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n","  array([ 101, 1963, 3560, 7539, 8024,  791, 1921, 1343, 6859, 2798, 4692,\n","         1168, 4638, 8024, 1963,  678, 1756, 2792, 4850,  131,  855, 5390,\n","         1762, 6205, 2254, 1281, 4031, 1366, 6662,  753, 3667, 8966, 5998,\n","          511, 2208,  749,  671,  943, 1377,  809, 4692, 3292, 4638, 1765,\n","         3175,  749,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0], dtype=int32)>,\n","  'token_type_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n","  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0], dtype=int32)>},\n"," <tf.Tensor: shape=(), dtype=int64, numpy=1>)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"cK_qmO5q2mhY"},"source":["### Parameter settings\n","\n","在 `tf.data.Dataset` 中，通常會在訓練資料集後面接上三個標準的操作：\n","\n","* `.shuffle()`: 打亂資料集的方式，會先從資料集中隨機抽取`buffer_size`筆資料進去 `buffer`，然後再 `buffer` 從中抽取`batch_size`筆資料進行訓練，丟進 `buffer` 的步驟主要是在處理無法一次將所有資料集丟進記憶體進行訓練的情形。\n","\n","* `.batch()`: 每次迭代使用的資料數量。\n","* `.repeat()`: `epochs` 數量。"]},{"cell_type":"code","metadata":{"id":"LnkgH9b1aMQh"},"source":["buffer_size = 100\n","train_bz = 12\n","epochs = 3\n","valid_bz = 12\n","\n","train_gen = train_dataset.shuffle(buffer_size).batch(train_bz).repeat(epochs)\n","valid_gen = valid_dataset.batch(valid_bz)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"obeWX_mWaMQh"},"source":["optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5,\n","                                     epsilon=1e-8,\n","                                     clipnorm=1.0)\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n","                                                     reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)\n","model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TXgwUr-w2sMt"},"source":["## Training\n","\n","* `.fit()`: 支援 `generator` 的輸入方式，也可以用 `fit_generator` 。\n","* `steps_per_epoch`: 每個 `epoch` 訓練幾次，通常是 $\\frac{train\\_size}{batch\\_size}$ ，遍歷整個訓練集。\n","* `validation_steps`: 與 `steps_per_epoch` 同義。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ODYvhGCpaMQh","executionInfo":{"status":"ok","timestamp":1605776185492,"user_tz":-480,"elapsed":832735,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"1ec86729-e1a0-437d-caa2-20a3b4c050a5"},"source":["history = model.fit(train_gen,\n","                    epochs=epochs,\n","                    steps_per_epoch=train_size//train_bz, \n","                    validation_data=valid_gen,\n","                    validation_steps=valid_size//valid_bz)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","471/471 [==============================] - 272s 577ms/step - loss: 0.1761 - accuracy: 0.9517 - val_loss: 0.1497 - val_accuracy: 0.9484\n","Epoch 2/3\n","471/471 [==============================] - 268s 569ms/step - loss: 0.1249 - accuracy: 0.9642 - val_loss: 0.1361 - val_accuracy: 0.9668\n","Epoch 3/3\n","471/471 [==============================] - 269s 572ms/step - loss: 0.0850 - accuracy: 0.9750 - val_loss: 0.1467 - val_accuracy: 0.9654\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3SYqv34CaMQh"},"source":["## Save model"]},{"cell_type":"code","metadata":{"id":"wJ4nvDhzaMQh"},"source":["save_path = 'save_chinese'\n","if not os.path.exists(save_path):\n","    os.mkdir(save_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K7V2HUXaaMQh"},"source":["model.save_pretrained('./save_chinese/')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H2kkhevxaMQh"},"source":["## Evaluation\n","\n","畫出`precision`, `recall`, `f1-score`以及`confusion matrix`評估模型表現。"]},{"cell_type":"code","metadata":{"id":"o3wC630DaMQh"},"source":["valid_pred = model.predict(valid_gen)\n","valid_pred_ids = np.argmax(valid_pred[0], axis=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IuiIbM07aMQh"},"source":["import numpy as np\n","\"\"\"\n","從 tf.data.Dataset 中拿取 label\n","\"\"\"\n","valid_label = list()\n","for x in valid_gen:\n","  valid_label.append(x[1].numpy())\n","valid_label = np.concatenate(valid_label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZrJlng1WaMQh","executionInfo":{"status":"ok","timestamp":1605776449974,"user_tz":-480,"elapsed":28204,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"7045740d-82aa-4914-fb13-cd3b685e408b"},"source":["print(classification_report(y_pred=valid_pred_ids, y_true=valid_label))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.39      0.48        59\n","           1       0.97      0.99      0.98      1360\n","\n","    accuracy                           0.97      1419\n","   macro avg       0.81      0.69      0.73      1419\n","weighted avg       0.96      0.97      0.96      1419\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"sskdi4DbaMQh","executionInfo":{"status":"ok","timestamp":1605776592752,"user_tz":-480,"elapsed":947,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"57803791-d239-44e7-fc51-6d68925a910d"},"source":["confm = confusion_matrix(y_pred=valid_pred_ids, y_true=valid_label)\n","\n","index = ['Actual_0', 'Actual_1']\n","columns = ['Pred_0', 'Pred_1']\n","pd.DataFrame(confm, index=index, columns=columns)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pred_0</th>\n","      <th>Pred_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Actual_0</th>\n","      <td>23</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>Actual_1</th>\n","      <td>13</td>\n","      <td>1347</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          Pred_0  Pred_1\n","Actual_0      23      36\n","Actual_1      13    1347"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"1WnDrLPQaMQh"},"source":["## Load model and predict"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NGS1-lQ_aMQh","executionInfo":{"status":"ok","timestamp":1605776657030,"user_tz":-480,"elapsed":61802,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"98b21496-b2b2-4ed8-bfca-63a161443a71"},"source":["new_model = TFBertForSequenceClassification.from_pretrained('save_chinese/')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at save_chinese/ were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n","- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at save_chinese/ and are newly initialized: ['dropout_75']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"FY19hevGaMQh"},"source":["sentence = [\"文瑋助教好壯\"]\n","\n","test_dataset = pd.DataFrame(dict(idx=list(range(len(sentence))),\n","                                 label=[0]*len(sentence),\n","                                 sentence=sentence))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":77},"id":"vFvvO13VaMQh","executionInfo":{"status":"ok","timestamp":1605776657047,"user_tz":-480,"elapsed":59074,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"04065a5c-81fe-4f8e-e6c9-f95e8c28ab4a"},"source":["test_dataset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>idx</th>\n","      <th>label</th>\n","      <th>sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>文瑋助教好壯</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   idx  label sentence\n","0    0      0   文瑋助教好壯"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"t2S2nLdWaMQh"},"source":["test_gen = tf.data.Dataset.from_tensor_slices(dict(test_dataset))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vYrxtbR9aMQh","executionInfo":{"status":"ok","timestamp":1605776657050,"user_tz":-480,"elapsed":57330,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"7be68ca9-a607-4ea7-b0db-4a34044021eb"},"source":["max_length = 512\n","task = 'cola'\n","test_gen = glue_convert_examples_to_features(test_gen, tokenizer, max_length, task)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/processors/glue.py:67: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/processors/glue.py:284: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"gB1CjFcuaMQh"},"source":["test_gen = test_gen.batch(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_QOsCfzxaMQh","executionInfo":{"status":"ok","timestamp":1605776657052,"user_tz":-480,"elapsed":56731,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"f442dd7f-1c92-455a-d4f4-580528a6b111"},"source":["next(iter(test_gen))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'attention_mask': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n","  array([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0]], dtype=int32)>,\n","  'input_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n","  array([[ 101, 3152, 4441, 1221, 3136, 1962, 1897,  102,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0]], dtype=int32)>,\n","  'token_type_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n","  array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0]], dtype=int32)>},\n"," <tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>)"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"Ha9gB2DlaMQh"},"source":["pred = new_model.predict(test_gen)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qVk_qu9taMQh"},"source":["pred_ids = np.argmax(pred, axis=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jujjP3rEaMQh","executionInfo":{"status":"ok","timestamp":1605776659289,"user_tz":-480,"elapsed":56824,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"c0f8f6de-25c1-4795-9ac5-6522814f6d2d"},"source":["print(pred_ids[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MD9qed9ZaMQh"},"source":[""],"execution_count":null,"outputs":[]}]}