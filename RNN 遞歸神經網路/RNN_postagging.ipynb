{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"RNN_postagging.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ceSXK8yNddSW","executionInfo":{"status":"ok","timestamp":1604477947740,"user_tz":-480,"elapsed":1582,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"31ec9718-46be-45c7-9a16-f1c8cce4afdf","colab":{"base_uri":"https://localhost:8080/"}},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Wed Nov  4 08:19:06 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9KnJKDSXih67","executionInfo":{"status":"ok","timestamp":1604477948248,"user_tz":-480,"elapsed":2075,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"99e460c6-e9e4-4e64-b321-b9c7fd45181c","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oyGlKD-vGrk0"},"source":["* @file NLP進階 / RNN_postagging\n","  * @brief RNN_postagging 模型實作 \n","\n","  * 此份程式碼是以教學為目的，附有完整的架構解說。\n","\n","  * @author 人工智慧科技基金會 AI 工程師 - 康文瑋\n","  * Email: run963741@aif.tw\n","  * Resume: https://www.cakeresume.com/run963741\n","\n","  * 最後更新日期: 2020/11/13"]},{"cell_type":"markdown","metadata":{"id":"U2GFcGjUloYa"},"source":["# Recurrent Neural Network\n","\n","遞歸神經網路擅長處理序列任務，接下來我們要實作的類型是 `many to many`，也就是輸入一串長度為 `n` 的序列給模型，預測一串長度為 `n` 的序列給模型。 \n","\n","* 看圖說故事 (Image captioning): 輸入一張圖片，輸出該張圖片的描述。\n","* 詞性標註 (Part-of-Speech tagging): 輸入一段句子，輸出每個詞的詞性。"]},{"cell_type":"markdown","metadata":{"id":"uKNeHfZslHyS"},"source":["<figure>\n","<center>\n","<img src='https://drive.google.com/uc?export=view&id=1WREpRnryegmSURXPoCeJo5-RIRqkiWlv' width=\"800\"/>\n","<figcaption>Many\\One to many</figcaption></center>\n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"fdV_IwYoDTOi"},"source":["# 載入函數"]},{"cell_type":"code","metadata":{"id":"I67ngzd2DTOp"},"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import os\n","\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from nltk.corpus import treebank, brown, conll2000\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","%matplotlib inline\n","\n","os.chdir('/content/drive/Shared drives/類技術班教材/標準版/NLP進階/RNN 遞歸神經網路')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PBG9CcvlDTO6"},"source":["# 載入資料集\n","\n","我們使用的是 `NLTK` 套件自帶的資料集，`NLTK` 是外國很知名的自然語言處理套件，支援諸多的自然語言處理流程、任務，例如斷詞 (Tokenization)、詞性標註 (Part of speech tagging)等等。\n","\n","我們要使用的是 `NLTK` 中的詞性標註資料集，分別是 `treebank`, `brown`, `conll2000`。"]},{"cell_type":"code","metadata":{"id":"scM3b5S9iTTM","executionInfo":{"status":"ok","timestamp":1604477950149,"user_tz":-480,"elapsed":3951,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"8f50608c-0701-4021-9ade-a392849b1334","colab":{"base_uri":"https://localhost:8080/"}},"source":["import nltk\n","nltk.download('treebank')\n","nltk.download('brown')\n","nltk.download('conll2000')\n","nltk.download('universal_tagset')\n","nltk.download('tagsets')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package treebank to /root/nltk_data...\n","[nltk_data]   Package treebank is already up-to-date!\n","[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Package brown is already up-to-date!\n","[nltk_data] Downloading package conll2000 to /root/nltk_data...\n","[nltk_data]   Package conll2000 is already up-to-date!\n","[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n","[nltk_data]   Package universal_tagset is already up-to-date!\n","[nltk_data] Downloading package tagsets to /root/nltk_data...\n","[nltk_data]   Package tagsets is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"fPQAzCYwDTO9"},"source":["tree_bank = treebank.tagged_sents(tagset='universal')\n","brown_corpus = brown.tagged_sents(tagset='universal')\n","conll_corpus = conll2000.tagged_sents(tagset='universal')\n","tagged_sents = tree_bank + brown_corpus + conll_corpus"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CB-IqrdFoopS"},"source":["使用 `nltk.help.upenn_tagset()` 可以列出所有詞性標註的標籤解釋。"]},{"cell_type":"code","metadata":{"id":"rm2dKWNGkeQo","executionInfo":{"status":"ok","timestamp":1604477950151,"user_tz":-480,"elapsed":3899,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"178c51a9-dd38-461f-efb0-c8505bee2c68","colab":{"base_uri":"https://localhost:8080/"}},"source":["nltk.help.upenn_tagset()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["$: dollar\n","    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n","'': closing quotation mark\n","    ' ''\n","(: opening parenthesis\n","    ( [ {\n","): closing parenthesis\n","    ) ] }\n",",: comma\n","    ,\n","--: dash\n","    --\n",".: sentence terminator\n","    . ! ?\n",":: colon or ellipsis\n","    : ; ...\n","CC: conjunction, coordinating\n","    & 'n and both but either et for less minus neither nor or plus so\n","    therefore times v. versus vs. whether yet\n","CD: numeral, cardinal\n","    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n","    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n","    fifteen 271,124 dozen quintillion DM2,000 ...\n","DT: determiner\n","    all an another any both del each either every half la many much nary\n","    neither no some such that the them these this those\n","EX: existential there\n","    there\n","FW: foreign word\n","    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n","    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n","    terram fiche oui corporis ...\n","IN: preposition or conjunction, subordinating\n","    astride among uppon whether out inside pro despite on by throughout\n","    below within for towards near behind atop around if like until below\n","    next into if beside ...\n","JJ: adjective or numeral, ordinal\n","    third ill-mannered pre-war regrettable oiled calamitous first separable\n","    ectoplasmic battery-powered participatory fourth still-to-be-named\n","    multilingual multi-disciplinary ...\n","JJR: adjective, comparative\n","    bleaker braver breezier briefer brighter brisker broader bumper busier\n","    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n","    cozier creamier crunchier cuter ...\n","JJS: adjective, superlative\n","    calmest cheapest choicest classiest cleanest clearest closest commonest\n","    corniest costliest crassest creepiest crudest cutest darkest deadliest\n","    dearest deepest densest dinkiest ...\n","LS: list item marker\n","    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n","    SP-44007 Second Third Three Two * a b c d first five four one six three\n","    two\n","MD: modal auxiliary\n","    can cannot could couldn't dare may might must need ought shall should\n","    shouldn't will would\n","NN: noun, common, singular or mass\n","    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n","    investment slide humour falloff slick wind hyena override subhumanity\n","    machinist ...\n","NNP: noun, proper, singular\n","    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n","    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n","    Shannon A.K.C. Meltex Liverpool ...\n","NNPS: noun, proper, plural\n","    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n","    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n","    Apache Apaches Apocrypha ...\n","NNS: noun, common, plural\n","    undergraduates scotches bric-a-brac products bodyguards facets coasts\n","    divestitures storehouses designs clubs fragrances averages\n","    subjectivists apprehensions muses factory-jobs ...\n","PDT: pre-determiner\n","    all both half many quite such sure this\n","POS: genitive marker\n","    ' 's\n","PRP: pronoun, personal\n","    hers herself him himself hisself it itself me myself one oneself ours\n","    ourselves ownself self she thee theirs them themselves they thou thy us\n","PRP$: pronoun, possessive\n","    her his mine my our ours their thy your\n","RB: adverb\n","    occasionally unabatingly maddeningly adventurously professedly\n","    stirringly prominently technologically magisterially predominately\n","    swiftly fiscally pitilessly ...\n","RBR: adverb, comparative\n","    further gloomier grander graver greater grimmer harder harsher\n","    healthier heavier higher however larger later leaner lengthier less-\n","    perfectly lesser lonelier longer louder lower more ...\n","RBS: adverb, superlative\n","    best biggest bluntest earliest farthest first furthest hardest\n","    heartiest highest largest least less most nearest second tightest worst\n","RP: particle\n","    aboard about across along apart around aside at away back before behind\n","    by crop down ever fast for forth from go high i.e. in into just later\n","    low more off on open out over per pie raising start teeth that through\n","    under unto up up-pp upon whole with you\n","SYM: symbol\n","    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n","TO: \"to\" as preposition or infinitive marker\n","    to\n","UH: interjection\n","    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n","    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n","    man baby diddle hush sonuvabitch ...\n","VB: verb, base form\n","    ask assemble assess assign assume atone attention avoid bake balkanize\n","    bank begin behold believe bend benefit bevel beware bless boil bomb\n","    boost brace break bring broil brush build ...\n","VBD: verb, past tense\n","    dipped pleaded swiped regummed soaked tidied convened halted registered\n","    cushioned exacted snubbed strode aimed adopted belied figgered\n","    speculated wore appreciated contemplated ...\n","VBG: verb, present participle or gerund\n","    telegraphing stirring focusing angering judging stalling lactating\n","    hankerin' alleging veering capping approaching traveling besieging\n","    encrypting interrupting erasing wincing ...\n","VBN: verb, past participle\n","    multihulled dilapidated aerosolized chaired languished panelized used\n","    experimented flourished imitated reunifed factored condensed sheared\n","    unsettled primed dubbed desired ...\n","VBP: verb, present tense, not 3rd person singular\n","    predominate wrap resort sue twist spill cure lengthen brush terminate\n","    appear tend stray glisten obtain comprise detest tease attract\n","    emphasize mold postpone sever return wag ...\n","VBZ: verb, present tense, 3rd person singular\n","    bases reconstructs marks mixes displeases seals carps weaves snatches\n","    slumps stretches authorizes smolders pictures emerges stockpiles\n","    seduces fizzes uses bolsters slaps speaks pleads ...\n","WDT: WH-determiner\n","    that what whatever which whichever\n","WP: WH-pronoun\n","    that what whatever whatsoever which who whom whosoever\n","WP$: WH-pronoun, possessive\n","    whose\n","WRB: Wh-adverb\n","    how however whence whenever where whereby whereever wherein whereof why\n","``: opening quotation mark\n","    ` ``\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4Js934R-pDFZ"},"source":["## 資料格式"]},{"cell_type":"markdown","metadata":{"id":"ONYj7QbipGk2"},"source":["`NLTK` 的資料格式為 `(word, tagging)`。"]},{"cell_type":"code","metadata":{"id":"RBc3LLF4DTPJ","executionInfo":{"status":"ok","timestamp":1604477957457,"user_tz":-480,"elapsed":11190,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"e60a479c-61b3-4801-bd0f-6882ddd6b7b3","colab":{"base_uri":"https://localhost:8080/"}},"source":["tagged_sents[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Pierre', 'NOUN'),\n"," ('Vinken', 'NOUN'),\n"," (',', '.'),\n"," ('61', 'NUM'),\n"," ('years', 'NOUN'),\n"," ('old', 'ADJ'),\n"," (',', '.'),\n"," ('will', 'VERB'),\n"," ('join', 'VERB'),\n"," ('the', 'DET'),\n"," ('board', 'NOUN'),\n"," ('as', 'ADP'),\n"," ('a', 'DET'),\n"," ('nonexecutive', 'ADJ'),\n"," ('director', 'NOUN'),\n"," ('Nov.', 'NOUN'),\n"," ('29', 'NUM'),\n"," ('.', '.')]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"m8FsYHxfDTQG"},"source":["# 資料前處理\n","\n","這邊將每個句子中的 `word` 和 `tagging` 個別挑出來。"]},{"cell_type":"code","metadata":{"id":"xuPZrzMHzfJk","executionInfo":{"status":"ok","timestamp":1604477963943,"user_tz":-480,"elapsed":17664,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"6dfc0914-6a52-4673-82e8-439454599f29","colab":{"base_uri":"https://localhost:8080/"}},"source":["words = list()\n","tags = list()\n","for tagged_sent in tqdm(tagged_sents):\n","  word = [t[0] for t in tagged_sent]\n","  tag = [t[1] for t in tagged_sent]\n","\n","  words.append(word)\n","  tags.append(tag)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 72202/72202 [00:05<00:00, 13024.90it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"OCLPazqa2IsS","executionInfo":{"status":"ok","timestamp":1604477963944,"user_tz":-480,"elapsed":17650,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"aaede4e0-6c8f-415b-a4fd-1ea0271cd6ec","colab":{"base_uri":"https://localhost:8080/"}},"source":["print_index = 0\n","print(words[print_index])\n","print('-'*16)\n","print(tags[print_index])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n","----------------\n","['NOUN', 'NOUN', '.', 'NUM', 'NOUN', 'ADJ', '.', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'NUM', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"18JDtHq1lHyB"},"source":["### 建立字典 (vocabulary)\n","\n","所有 NLP 模型都需要建立字典，在字典中會紀錄所有不重複的詞以及詞的 `index`，例如：\n","\n","$$\n","\\begin{aligned}\n","自然 : 0 \\\\\n","語言 : 1 \\\\\n","處理 : 2 \n","\\end{aligned}\n","$$\n","\n","記錄這些詞的目的是為了跟 `word embedding` 做匹配，在訓練模型時，會先將句子中的每個詞透過字典轉換為 `index`，然後再轉換成 `word embedding`，接著輸入模型進行訓練。"]},{"cell_type":"code","metadata":{"id":"Q1m4M8h66S2z"},"source":["def set_vocab(words):\n","  set_words = list(set([t1 for t2 in words for t1 in t2]))\n","  words_index = np.array(range(len(set_words))) + 1 # + 1 表示從 1 開始做 word index\n","  word_to_index = dict(zip(set_words, words_index))\n","  index_to_word = dict(zip(words_index, set_words))\n","\n","  return word_to_index, index_to_word"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"okzo58jf9Vlj"},"source":["word_to_index, index_to_word = set_vocab(words)\n","tag_to_index, index_to_tag = set_vocab(tags)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Oko5Z8_OW_X"},"source":["word_vocab_size = list(index_to_word)[-1] + 1\n","tag_vocab_size = list(index_to_tag)[-1] + 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"umL-RrS6MDiw","executionInfo":{"status":"ok","timestamp":1604477964457,"user_tz":-480,"elapsed":18129,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"0e73dfa4-b22e-4b71-dc43-886cbba27dce","colab":{"base_uri":"https://localhost:8080/"}},"source":["print('Word vocabulary size: ', word_vocab_size)\n","print('Tag vocabulary size: ', tag_vocab_size)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Word vocabulary size:  67068\n","Tag vocabulary size:  13\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RqkjPicsnKP9"},"source":["在字典中，會以 `dictionary` 的資料格式來儲存每個詞。"]},{"cell_type":"code","metadata":{"id":"dt15n6jJF4BH","executionInfo":{"status":"ok","timestamp":1604477964458,"user_tz":-480,"elapsed":18119,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"0637f7d3-0f57-469b-aa70-75aa9395d325","colab":{"base_uri":"https://localhost:8080/"}},"source":["tag_to_index"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'.': 1,\n"," 'ADJ': 3,\n"," 'ADP': 11,\n"," 'ADV': 5,\n"," 'CONJ': 12,\n"," 'DET': 2,\n"," 'NOUN': 7,\n"," 'NUM': 6,\n"," 'PRON': 8,\n"," 'PRT': 4,\n"," 'VERB': 9,\n"," 'X': 10}"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"z3vLlAt0ENmm"},"source":["## 訓練集 (Train) 與測試集 (Test) 切割\n","\n","因為後面需要將資料轉換為 `tf.data` 格式，所以這邊切訓練集以及測試集時需要使用 `' '` 將 `list` 轉換為字串，才能夠輸入給 `.from_tensor_slices`。"]},{"cell_type":"code","metadata":{"id":"Eo8V1qn4CPEJ"},"source":["X_train, X_test, y_train, y_test = train_test_split([' '.join(w) for w in words], \n","                                                    [' '.join(w) for w in tags], test_size=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O3pGWyN4Cw8e","executionInfo":{"status":"ok","timestamp":1604477964460,"user_tz":-480,"elapsed":18104,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"9ad7630c-e6ca-4237-e857-186f0fe8c549","colab":{"base_uri":"https://localhost:8080/"}},"source":["print('Training data size: %d' % len(X_train))\n","print('Testing data size: %d' % len(X_test))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training data size: 57761\n","Testing data size: 14441\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t0EoP99wnTvn"},"source":["### Tensorflow data pipeline\n","\n","`tf.data` 是 `tensorflow` 專用的訓練格式，能夠加速訓練過程。"]},{"cell_type":"code","metadata":{"id":"aaqrEFlizfPs"},"source":["# from_tensor_slices 裡面放的是 (資料, 標籤)\n","train_tfdata = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n","test_tfdata = tf.data.Dataset.from_tensor_slices((X_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-c4TlLYbJ4Ug"},"source":["# tf.data 可以使用 generator 的方式來獲取資料\n","x = iter(train_tfdata)\n","tmp_inp = next(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ELTO-hHK1Go","executionInfo":{"status":"ok","timestamp":1604477966464,"user_tz":-480,"elapsed":20081,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"5ddff2c6-7fa7-44fb-be90-c97d0f358d08","colab":{"base_uri":"https://localhost:8080/"}},"source":["# tf.data 裡都是以 tf.Tensor 的格式\n","tmp_inp"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(), dtype=string, numpy=b'As a groundwork for the proposal I give some attention to the first task enumerated above , the clarification of goal .'>,\n"," <tf.Tensor: shape=(), dtype=string, numpy=b'ADP DET NOUN ADP DET NOUN PRON VERB DET NOUN ADP DET ADJ NOUN VERB ADV . DET NOUN ADP NOUN .'>)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"GaNNbXLgI1aT"},"source":["### 資料前處理"]},{"cell_type":"markdown","metadata":{"id":"1vXhezVOU26C"},"source":["#### tf.py_function\n","\n","若在 `pipeline` 中含有不為 `tensorflow` 的操作方式，就必須使用 `tf.py_function` 將函數的輸入輸出轉換為 `tf.data`。"]},{"cell_type":"code","metadata":{"id":"lqhI1QMrI1fB"},"source":["# 將 word 和 tag 使用 ' ' 分開來\n","def encode(word, tag):\n","  word = [word_to_index[t] for t in word.numpy().decode().split(' ')]\n","  tag = [tag_to_index[t] for t in tag.numpy().decode().split(' ')]\n","  return word, tag\n","\n","# 使用 tf.py_function 將 encode 轉換為 tf.data\n","def tf_encode(word, tag):\n","  return tf.py_function(encode, [word, tag], [tf.int32, tf.int32])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"clZINiNxWetG"},"source":["https://www.tensorflow.org/datasets/performances\n","\n","* `.map`: 常常使用函數來資料前處理\n","* `.cache`: 預先將資料放進記憶體加速\n","* `.shuffle`: 指定 `buffer_size` \b預先放進去記憶體，這樣每次拿 `batch_size` 筆加速運算。\n","* `padded_batch`: 指定 `batch_size`，還能夠指定 `padded_shapes`，將所有句子都補 0 至統一長度。"]},{"cell_type":"code","metadata":{"id":"bm-wNZrVI7Ob"},"source":["buffer_size = 320\n","batch_size = 32\n","\n","padded_shapes = (tf.TensorShape([None]), tf.TensorShape([None]))\n","\n","train_generator = train_tfdata.map(tf_encode, num_parallel_calls=tf.data.experimental.AUTOTUNE).cache().shuffle(buffer_size).padded_batch(batch_size, padded_shapes=padded_shapes).repeat()\n","test_generator = test_tfdata.map(tf_encode, num_parallel_calls=tf.data.experimental.AUTOTUNE).padded_batch(batch_size, padded_shapes=padded_shapes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bLbngCA_Khht"},"source":["x = iter(train_generator)\n","tmp_inp = next(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OYOrs-OpKjnd","executionInfo":{"status":"ok","timestamp":1604477966469,"user_tz":-480,"elapsed":20053,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"5e1a7580-ba13-4c64-b338-bf2699c07267","colab":{"base_uri":"https://localhost:8080/"}},"source":["tmp_inp"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(32, 55), dtype=int32, numpy=\n"," array([[21466, 46086, 48164, ...,     0,     0,     0],\n","        [16201, 48178, 45380, ...,     0,     0,     0],\n","        [21466, 40685, 54125, ...,     0,     0,     0],\n","        ...,\n","        [21466,  9326, 48178, ...,     0,     0,     0],\n","        [52813, 52823, 24361, ...,     0,     0,     0],\n","        [38169, 19411,  9013, ...,     0,     0,     0]], dtype=int32)>,\n"," <tf.Tensor: shape=(32, 55), dtype=int32, numpy=\n"," array([[1, 9, 8, ..., 0, 0, 0],\n","        [5, 1, 8, ..., 0, 0, 0],\n","        [1, 8, 9, ..., 0, 0, 0],\n","        ...,\n","        [1, 5, 1, ..., 0, 0, 0],\n","        [2, 3, 7, ..., 0, 0, 0],\n","        [7, 9, 9, ..., 0, 0, 0]], dtype=int32)>)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"jCmAKVQHDTV-"},"source":["## 建立模型\n","\n","tensorflow 提供三種建立模型的方法：\n","\n","1. Sequential API\n","2. Functional API\n","3. Model Subclassing\n","\n","以下為 Model Subclassing 的寫法。"]},{"cell_type":"code","metadata":{"id":"abXO6TMQDTWb"},"source":["class postag_rnn(tf.keras.Model):\n","  \"\"\"\n","  model subclassing 的寫法要使用繼承，繼承 tf.keras.Model\n","  這樣才能使用 model.fit, model.predict 等等函數\n","  \"\"\"\n","  def __init__(self, embedding_size, rnn_units):\n","    super().__init__()\n","    # 建立 word embedding lookup\n","    self.embedding = tf.keras.layers.Embedding(input_dim=word_vocab_size, output_dim=embedding_size)\n","    # 建立 lstm 模型\n","    self.lstm = tf.keras.layers.LSTM(rnn_units, recurrent_initializer='glorot_uniform', return_sequences=True)\n","    # 建立輸出層\n","    output_layer = tf.keras.layers.Dense(units=tag_vocab_size, activation='softmax')\n","    # 因為每個位置都要預測，所以要使用 TimeDistributed，重複利用 output_layer\n","    self.timedistributed = tf.keras.layers.TimeDistributed(output_layer)\n","\n","  def call(self, x):\n","    \"\"\"\n","    \bembedding: 將每個字轉換成向量，一個句子就變成矩陣\n","    lstm: 每個詞向量依序輸入模型，每個位置依序輸出 hidden state\n","    timedistributed: 每個 hidden state 輸入全連結層，輸出長度為 vocab_size 的向量\n","    \"\"\"\n","    embedded = self.embedding(x)\n","    hidden_states = self.lstm(embedded)\n","    outputs = self.timedistributed(hidden_states)\n","\n","    return outputs\n","\n","  def _model(self):\n","        x = tf.keras.layers.Input(shape=(20))\n","        return tf.keras.Model(inputs=[x], outputs=self.call(x))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"giMsHpwX0_Y0","executionInfo":{"status":"ok","timestamp":1604477966987,"user_tz":-480,"elapsed":20555,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"e890ab1c-2574-4eac-ef9b-3d0c287d45e9","colab":{"base_uri":"https://localhost:8080/"}},"source":["embedding_size = 256\n","rnn_units = 512\n","\n","tmp_model = postag_rnn(embedding_size, rnn_units)\n","tmp_model._model().summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 20)]              0         \n","_________________________________________________________________\n","embedding (Embedding)        (None, 20, 256)           17169408  \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 20, 512)           1574912   \n","_________________________________________________________________\n","time_distributed (TimeDistri (None, 20, 13)            6669      \n","=================================================================\n","Total params: 18,750,989\n","Trainable params: 18,750,989\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rNV08OwMDTW7"},"source":["## 編譯模型"]},{"cell_type":"code","metadata":{"id":"V4fF_bJfDTW8"},"source":["embedding_size = 256\n","rnn_units = 512\n","\n","model = postag_rnn(embedding_size, rnn_units)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n","\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WI9f4lGwUz2d"},"source":["## Callbacks"]},{"cell_type":"code","metadata":{"id":"o-LEcrAMUzZM"},"source":["model_path = './save_model/checkpoints_postag_model.keras'  # 模型儲存的位置\n","\n","# 建立 Checkpoint\n","checkpoint = tf.keras.callbacks.ModelCheckpoint(model_path,\n","                                                verbose=1,\n","                                                monitor='val_loss',    # 儲存模型的指標\n","                                                save_best_only=True,  # 是否只儲存最好的\n","                                                mode='min')           # 與指標搭配模式"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EsFw6Zx8DTXB"},"source":["## 訓練模型"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"HVWpokcqDTXB","executionInfo":{"status":"ok","timestamp":1604479372909,"user_tz":-480,"elapsed":1426446,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"782bbdd4-8de4-4109-c360-d87263d52aa9","colab":{"base_uri":"https://localhost:8080/"}},"source":["model.fit(train_generator, \n","          epochs=5, \n","          validation_data=test_generator, \n","          steps_per_epoch = len(X_train) // batch_size + 1,\n","          callbacks = [checkpoint])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","1806/1806 [==============================] - ETA: 0s - loss: 0.1444 - accuracy: 0.9556\n","Epoch 00001: val_loss improved from inf to 0.05211, saving model to ./save_model/checkpoints_postag_model.keras\n","1806/1806 [==============================] - 310s 172ms/step - loss: 0.1444 - accuracy: 0.9556 - val_loss: 0.0521 - val_accuracy: 0.9823\n","Epoch 2/5\n","1806/1806 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9877\n","Epoch 00002: val_loss improved from 0.05211 to 0.04751, saving model to ./save_model/checkpoints_postag_model.keras\n","1806/1806 [==============================] - 284s 157ms/step - loss: 0.0353 - accuracy: 0.9877 - val_loss: 0.0475 - val_accuracy: 0.9843\n","Epoch 3/5\n","1806/1806 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9909\n","Epoch 00003: val_loss did not improve from 0.04751\n","1806/1806 [==============================] - 271s 150ms/step - loss: 0.0259 - accuracy: 0.9909 - val_loss: 0.0491 - val_accuracy: 0.9847\n","Epoch 4/5\n","1806/1806 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9930\n","Epoch 00004: val_loss did not improve from 0.04751\n","1806/1806 [==============================] - 268s 149ms/step - loss: 0.0205 - accuracy: 0.9930 - val_loss: 0.0527 - val_accuracy: 0.9842\n","Epoch 5/5\n","1806/1806 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9946\n","Epoch 00005: val_loss did not improve from 0.04751\n","1806/1806 [==============================] - 268s 149ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 0.0579 - val_accuracy: 0.9839\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f7140281748>"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"VIfdB9VBDTXK"},"source":["## 評估模型"]},{"cell_type":"code","metadata":{"id":"MjCHQNDFDTXL","executionInfo":{"status":"ok","timestamp":1604479395657,"user_tz":-480,"elapsed":1449185,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"7b219ebd-6eb9-42d4-ba95-cd87cd3e52a9","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 儲存預測結果\n","testing_preds = list()\n","# 儲存真實標籤 tag\n","testing_true = list()\n","\n","# 第一個迴圈預測預測整個句子\n","for test in tqdm(test_generator):\n","  words, tags = test\n","  testing_pred = model.predict(words)\n","  testing_pred_index = np.argmax(testing_pred, axis=-1)\n","  # 第二個迴圈將預測值以及真實標籤儲存起來\n","  for i in range(len(tags)):\n","    testing_preds.append([p for p in testing_pred_index[i] if p != 0])\n","    testing_true.append([p for p in tags[i].numpy() if p != 0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 452/452 [00:22<00:00, 19.75it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"4WEsdesXqskF"},"source":["# 印出第 5 筆\n","print_index = 5\n","\n","word = X_test[print_index]\n","pred = testing_preds[print_index]\n","true = testing_true[print_index]\n","\n","pred_tag = [index_to_tag[t] for t in pred]\n","true_tag = [index_to_tag[t] for t in true]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NOkSYgGTtZvg","executionInfo":{"status":"ok","timestamp":1604481172484,"user_tz":-480,"elapsed":704,"user":{"displayName":"康文瑋","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0kw0qBY7pljC_Bn7wCPKwga44ziqqbm67ccpq=s64","userId":"14275451592269779869"}},"outputId":"6ad7297b-4613-436a-9836-4a9d7b733dec","colab":{"base_uri":"https://localhost:8080/"}},"source":["print('Input words: \\n', word)\n","print('Prediction: \\n', pred_tag)\n","print('True: \\n', true_tag)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input words: \n"," School teachers , all too unprepared for the job they must do , will need demonstrators .\n","Prediction: \n"," ['NOUN', 'NOUN', '.', 'PRT', 'ADV', 'ADJ', 'ADP', 'DET', 'NOUN', 'PRON', 'VERB', 'VERB', '.', 'VERB', 'VERB', 'NOUN', '.']\n","True: \n"," ['NOUN', 'NOUN', '.', 'PRT', 'ADV', 'ADJ', 'ADP', 'DET', 'NOUN', 'PRON', 'VERB', 'VERB', '.', 'VERB', 'VERB', 'NOUN', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MRLeLv33w4oo"},"source":[""],"execution_count":null,"outputs":[]}]}